# 疫情关键词

__2017326603072 杨逸飞 17信息与计算科学一班__

## 1.数据分析与预处理

分析工具：__jupyter notebook__

* 首先拿到excel数据，我用pandas里面的pd.read_excel读取数据成一个DataFrame。因为有70MB+所以打开花了一段时间，总共有20多万条数据

* 利用isnull() 先判断数据里是否有空数据(nan) ，结果发现没有空数据，所以不需要进行替换操作
* 将第一列的word变成索引列

## 2.数据划分

![TIM截图20200408143040](C:\Users\Jefferey\Desktop\TIM截图20200408143040.png)

* 由于要分析1，2，3月的各自热词 所以我们首先要对数据进行划分 
* 利用pandas 里面的iloc方法 划分成三个dataframe 各自分析

## 3.数据分析

* 利用pandas的apply方法 对每一月的行数据求和 之后加到行尾

![](C:\Users\Jefferey\Desktop\TIM截图20200408143406.png)

* 随后抽出列索引index 和 col_sum数据 进行分析 按照总和的大小进行排序 选出__top100__的热词
* 由于有三个月的数据 所以我们要提取每个月的额有效信息 （比如：疫情就不算是有效信息）
* 接下来 我把每个月的top100 变成列表加起来(append) 转化成集合 把每个关键词按出现次数 为 1 2 3次进行有效的划分
* 通过集合的交并补 求出top100中 ：
  * 只在该月出现过的热词
  * 其中两个月出现过的热词
  * 每个月都出现过的热词
* 之后用pyecharts中的bar来做可视化 总共做了7个html文件 
  * 其中Jan/Feb/March.html表示1 2 3月单独出现的热词
  * common{$}.html 表示1 2 3月共同出现的热词 （因为有57个 一个放不下 所以分了三个来展示）
  * two_times.html 表示出现1 2 3月中某两月出现的热词

## 4.数据摘取

* 在common.html中 共同的热词当然是： __新型、肺炎、冠状病毒、病例、疫情、确诊、武汉、国家、隔离、检测、新冠等等__，<u>但是值得一提的是，在所有的共同中也有几个特例就是二月份，因为二月份的某些热词搜索人数比1 3月加起来都要高，代表性的有疫情防控、检测、企业</u>
* 因此也能从侧面说明二月份大家更关心的疫情防控方面的问题

![TIM截图20200408145346](C:\Users\Jefferey\Desktop\TIM截图20200408145346.png)

* 在Jan.html中 不难看出 一月份的热词：__湖北 武汉 原因 不明__;说明1月份的疫情刚刚开始 新闻报道大篇幅都是报道是湖北武汉地区比较严重

![TIM截图20200408145604](C:\Users\Jefferey\Desktop\TIM截图20200408145604.png)

* Feb.html 可以看出二月份 大家关注中心又落在了__小区 服务 一线 体温等等__ 也说明了大家已经开始居家隔离 主要的热词都是集中在如何抗击疫情的方面

![TIM截图20200408150115](C:\Users\Jefferey\Desktop\TIM截图20200408150115.png)

* Mar.html 热词主要是 __美国 输入 意大利 境外 全球__ 很明显 此时国内的疫情已经得到了有效的控制 大家的注意都放在了国外 大家很关心国外输入病例的问题

![TIM截图20200408150046](C:\Users\Jefferey\Desktop\TIM截图20200408150046.png)

* two_times.html	作用不同与前面两者 因为他可以更直观的看出每两个月变化的趋势 例如大家1月到2月对于疫情的关注度明显上升 主要中心落在隔离防治上 而后半段2月至3月 大家关注度也是在防疫 生活等反面

![TIM截图20200408150412](C:\Users\Jefferey\Desktop\TIM截图20200408150412.png)

## 5.总结

__总体来说 我的分析也只是抽取了前100的热词 大多数的总点击都在几千以上 因为热词一共有20多万个 很多都不是有效信息 很多信息点击人数也十分相近 难免会有误差;所以我只能做出大致的分析，对于预测 这一块 我觉得可能应该借助机器学习的方法可以实现 用回归来拟合数据 我之前做了点关于机器学习预测波士顿房价、糖尿病的案例 确实对于某些问题的分类效果不错 但是这个问题因为每个热词只对应一组数据所以预测确实不太准 肯恶搞海湖涉及到自然语言处理等等 这些问题只能以后再一一解决__

* 有一点问题的就是我 我曾经对1月的热词top10 试着用折线图去可视化数据 大致图像如下所示 因为数据过多的原因 一次拟合10个就已经很多 很多线已经分不清楚了 所以我便放弃了用折线图来表示趋势 ；不可否认的是确实折线图非常直观 但是要把热词放进去也是是不可能的。

![TIM截图20200408151138](C:\Users\Jefferey\Desktop\TIM截图20200408151138.png)

* 至于老师发的那种图 我确实不太会 也不知道是哪个库画出来的 但有点问题就是 excel里面的数据 我发现没有钟南山和邮轮 等等热词